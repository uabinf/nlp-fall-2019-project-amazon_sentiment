{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Domain Sentiment Analysis Study\n",
    "NLP Group Project\n",
    "\n",
    "Atulya Shetty, Payton Walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normalize data\n",
    "def imdb_data(test_size=0.2):\n",
    "    \"\"\" \n",
    "        Retrieves IMDB data movie review dataset\n",
    "        \n",
    "        Parameters:\n",
    "        test_size = float, optional (default=0.2)\n",
    "        \n",
    "        Returns:\n",
    "        Tuple containing training and test data for IMBD movie            [po;iuyreviews and their sentiment\n",
    "        \n",
    "    \"\"\"\n",
    "    imdb_file = 'data/imdb.csv'\n",
    "    imdb_df = pd.read_csv(imdb_file)\n",
    "    X, y = imdb_df.review, imdb_df.sentiment\n",
    "    return train_test_split(X, y, test_size= 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train_review, imdb_test_review, imdb_train_sent, imdb_test_sent = imdb_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normalize data\n",
    "def yelp_data():\n",
    "    \n",
    "    \"\"\" \n",
    "        Parameters:\n",
    "        test_size = float, optional (default=0.2)\n",
    "        \n",
    "        Returns:\n",
    "        Tuple containing training and test data for Yelp reviews\n",
    "        \n",
    "    \"\"\"\n",
    "    yelp_file = 'data/yelp.csv'\n",
    "    yelp_df = pd.read_csv(yelp_file)\n",
    "    X, y = yelp_df.text, yelp_df.stars\n",
    "    \"\"\"\n",
    "        Split into train, test and validation set\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    df = pd.concat([X_train, y_train], axis=1)\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "    df_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "        Save as csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(r'data/yelp_train.csv')\n",
    "    df_test.to_csv(r'data/yelp_test.csv')\n",
    "    df_val.to_csv(r'data/yelp_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns train test split for Amazon reviews\n",
    "\"\"\"\n",
    "def load_amz(test_size=0.20):\n",
    "    try:\n",
    "        with gzip.open(\"data/Amazon.pkl\", 'rb') as az:\n",
    "            reviews = pickle.load(az)\n",
    "            X, y = reviews.reviewText, reviews.overall\n",
    "            return train_test_split(X, y, test_size= test_size, random_state=1)\n",
    "    except FileNotFoundError:\n",
    "        \"\"\"\n",
    "            This block shouldn't execute since we should already have a  pickled file with Amazon reviews.\n",
    "            If the pickle file is missing for some reason, ensure that the Electronics_5.json is presnet.\n",
    "        \"\"\"\n",
    "        stream = pd.read_json('Electronics_5.json', lines = True, chunksize=10000)\n",
    "    \n",
    "        \"\"\"\n",
    "            Only extract reviews that are verified by Amazon and which have been voted helpful by users\n",
    "            Then filter out the review text and rating \n",
    "        \"\"\"\n",
    "\n",
    "        amazon_df = [df[(df.verified == True) & (df.vote.isna() == False)] \n",
    "                     for df in stream]\n",
    "        reviews_df = [df[['reviewText', 'overall']] for df in amazon_df[:150]]\n",
    "        reviews_df = pd.concat(reviews_df, sort=False)\n",
    "        \n",
    "        \"\"\"\n",
    "            Pickle the list so that we don't have extract the data again\n",
    "        \"\"\"\n",
    "        with gzip.open(\"data/Amazon.pkl\", \"wb\") as az:\n",
    "            pickle.dump(reviews_df, az)\n",
    "            X, y = reviews_df.reviewText, reviews_df.overall\n",
    "        return train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_train_review, amz_test_review, amz_train_ratings, amz_test_ratings = load_amz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

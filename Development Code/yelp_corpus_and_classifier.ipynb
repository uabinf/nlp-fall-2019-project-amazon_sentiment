{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create_Corpus_Test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcisnsYp2SVZ",
        "colab_type": "text"
      },
      "source": [
        "# **Create Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK4W1plE16fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tMwpXsAzQYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "32feab86-2b4e-4984-a8a1-6b96599edf3b"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "\n",
        "##Note: You will need to save your split CSV data files in the data_folder path with each file titled appropriately \n",
        "#       i.e. train.csv test.csv dev.csv. This is because the corpus initializers will automatically search for the \n",
        "#       train, dev, test splits in a folder.\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'data'\n",
        "\n",
        "# column format indicating which columns hold the text and label(s)\n",
        "column_name_map = {1: \"text\", 3: \"label_topic\"}\n",
        "\n",
        "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                         column_name_map,\n",
        "                                         skip_header=True,\n",
        "                                         delimiter=',',\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:17:22,412 Reading data from data\n",
            "2019-11-18 00:17:22,414 Train: data/train.csv\n",
            "2019-11-18 00:17:22,415 Dev: data/dev.csv\n",
            "2019-11-18 00:17:22,416 Test: data/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgksOzU12Ygp",
        "colab_type": "text"
      },
      "source": [
        "# **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRzLWM-W10W0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c16d3826-bd08-400c-bca4-b81b9be3fad7"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import IMDB\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 1. get the corpus\n",
        "#corpus: Corpus = IMDB().downsample(0.1)\n",
        "print(corpus)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus: 6000 train + 2000 dev + 2000 test sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LK9-acA2otV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1aa1340-a78a-4211-abcf-6a43b79bfe81"
      },
      "source": [
        "# 2. create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:13,765 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6000/6000 [00:19<00:00, 300.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:33,879 [b'1', b'0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KFyOYyL38sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3132c0f4-d6bd-4804-fdca-2712bcd5f878"
      },
      "source": [
        "# 3. make a list of word embeddings\n",
        "word_embeddings = [WordEmbeddings('glove'),\n",
        "\n",
        "                   # comment in flair embeddings for state-of-the-art results\n",
        "                   # FlairEmbeddings('news-forward'),\n",
        "                   # FlairEmbeddings('news-backward'),\n",
        "                   ]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:43,102 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpsahmaka1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:10<00:00, 15001658.61B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:54,461 copying /tmp/tmpsahmaka1 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:54,687 removing temp file /tmp/tmpsahmaka1\n",
            "2019-11-18 00:18:55,316 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmp0kz75q9c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:02<00:00, 9315156.17B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:18:58,324 copying /tmp/tmp0kz75q9c to cache at /root/.flair/embeddings/glove.gensim\n",
            "2019-11-18 00:18:58,347 removing temp file /tmp/tmp0kz75q9c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfs18Bz44Dtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4. initialize document embedding by passing list of word embeddings\n",
        "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
        "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                                     hidden_size=512,\n",
        "                                                                     reproject_words=True,\n",
        "                                                                     reproject_words_dimension=256,\n",
        "                                                                     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT10gpOW4JG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IY7Y-WJ4NRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(classifier, corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcHLw7H64PyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7. start the training\n",
        "  # 'resources/taggers/ag-news' is the location where you want to save your model files.\n",
        "trainer.train('resources/taggers/ag-news',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              anneal_factor=0.5,\n",
        "              patience=5,\n",
        "              max_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UicAfKIl8SQT",
        "colab_type": "text"
      },
      "source": [
        "# **Test:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp9AHjEF4Sj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e67ba8d2-6a9d-4ed1-ca4e-9afc76e879e2"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import TextClassifier\n",
        "\n",
        "classifier = TextClassifier.load('resources/taggers/ag-news/final-model.pt')\n",
        "\n",
        "# create example sentence\n",
        "sentence = Sentence('France is the current world cup winner.')\n",
        "\n",
        "# predict class and print\n",
        "classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-18 00:39:43,165 loading file resources/taggers/ag-news/final-model.pt\n",
            "[1 (0.7662146687507629)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIRmgwy38iqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMDB_Train-Amazon_Test.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9Ds_At2DplQD","colab_type":"text"},"source":["# **Classifier #1**\n","Train: IMDB  \n","Test: Amazon"]},{"cell_type":"markdown","metadata":{"id":"pcisnsYp2SVZ","colab_type":"text"},"source":["# **Create Corpus**"]},{"cell_type":"code","metadata":{"id":"qK4W1plE16fb","colab_type":"code","colab":{}},"source":["pip install flair"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tMwpXsAzQYz","colab_type":"code","outputId":"98ed2181-8e5a-4713-919f-775e39062c0a","executionInfo":{"status":"ok","timestamp":1574378915691,"user_tz":360,"elapsed":4732,"user":{"displayName":"Payton Walker","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPs1T6TM9X-ZFb3qy-FRZg_09KzlL2RwOi0ldjhA=s64","userId":"07447174154653828546"}},"colab":{"base_uri":"https://localhost:8080/","height":148}},"source":["from flair.data import Corpus\n","from flair.datasets import CSVClassificationCorpus\n","\n","##Note: You will need to save your split CSV data files in the data_folder path with each file titled appropriately \n","#       i.e. train.csv test.csv dev.csv. This is because the corpus initializers will automatically search for the \n","#       train, dev, test splits in a folder.\n","\n","# this is the folder in which train, test and dev files reside\n","data_folder = 'data'\n","\n","# column format indicating which columns hold the text and label(s)\n","column_name_map = {0: \"text\", 2: \"label_topic\"}\n","\n","# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n","corpus: Corpus = CSVClassificationCorpus(data_folder,\n","                                         column_name_map,\n","                                         skip_header=True,\n","                                         delimiter=',',\n",")"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2019-11-21 23:28:34,282 Reading data from data\n","2019-11-21 23:28:34,283 Train: data/train.csv\n","2019-11-21 23:28:34,284 Dev: data/dev.csv\n","2019-11-21 23:28:34,285 Test: data/test.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GgksOzU12Ygp","colab_type":"text"},"source":["# **Train Model**"]},{"cell_type":"code","metadata":{"id":"WRzLWM-W10W0","colab_type":"code","outputId":"a37efe5d-6c56-4530-ef77-f161da032c99","executionInfo":{"status":"ok","timestamp":1574379671287,"user_tz":360,"elapsed":479,"user":{"displayName":"Payton Walker","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPs1T6TM9X-ZFb3qy-FRZg_09KzlL2RwOi0ldjhA=s64","userId":"07447174154653828546"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from flair.data import Corpus\n","from flair.datasets import IMDB\n","from flair.embeddings import DocumentRNNEmbeddings, RoBERTaEmbeddings, XLNetEmbeddings\n","from flair.embeddings import StackedEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","\n","# 1. Print the corpus\n","print(corpus)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Corpus: 6831 train + 1708 dev + 37958 test sentences\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_LK9-acA2otV","colab_type":"code","outputId":"701bee17-7d8f-4421-d40a-0c9f19cc71ce","executionInfo":{"status":"ok","timestamp":1574379697286,"user_tz":360,"elapsed":23818,"user":{"displayName":"Payton Walker","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPs1T6TM9X-ZFb3qy-FRZg_09KzlL2RwOi0ldjhA=s64","userId":"07447174154653828546"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# 2. create the label dictionary\n","label_dict = corpus.make_label_dictionary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2019-11-21 23:41:13,106 Computing label dictionary. Progress:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6831/6831 [00:23<00:00, 295.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["2019-11-21 23:41:36,598 [b'1', b'0']\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_KFyOYyL38sR","colab_type":"code","colab":{}},"source":["# Initialize RoBERTa Embeddings\n","#roberta_embedding = RoBERTaEmbeddings(pretrained_model_name_or_path=\"roberta-base\", layers=\"0,1,2,3,4,5,6,7,8,9,10,11,12\", pooling_operation=\"first\", use_scalar_mix=True)\n","\n","# Initialize XLNet\n","#xlnet_embedding = XLNetEmbeddings('xlnet-base-cased')\n","\n","# 3. make a list of word embeddings\n","word_embeddings = [XLNetEmbeddings('xlnet-base-cased'), RoBERTaEmbeddings(pretrained_model_name_or_path=\"roberta-base\", layers=\"0,1,2,3,4,5,6,7,8,9,10,11,12\", pooling_operation=\"first\", use_scalar_mix=True)]\n","\n","#stacked_embeddings = StackedEmbeddings(embeddings=[roberta_embedding, xlnet_embedding])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfs18Bz44Dtv","colab_type":"code","colab":{}},"source":["# 4. initialize document embedding by passing list of word embeddings\n","# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n","document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n","                                                                     hidden_size=512,\n","                                                                     reproject_words=True,\n","                                                                     reproject_words_dimension=256,\n","                                                                     )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UT10gpOW4JG_","colab_type":"code","colab":{}},"source":["# 5. create the text classifier\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IY7Y-WJ4NRe","colab_type":"code","colab":{}},"source":["# 6. initialize the text classifier trainer\n","trainer = ModelTrainer(classifier, corpus)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcHLw7H64PyO","colab_type":"code","outputId":"5282a095-955c-45a6-e6ad-ba84258c529c","executionInfo":{"status":"error","timestamp":1574380169678,"user_tz":360,"elapsed":5338,"user":{"displayName":"Payton Walker","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPs1T6TM9X-ZFb3qy-FRZg_09KzlL2RwOi0ldjhA=s64","userId":"07447174154653828546"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 7. start the training\n","  # 'resources/taggers/sentiment-yelp' is the location where you want to save your model files.\n","trainer.train('resources/taggers/sentiment-yelp',\n","              learning_rate=0.1,\n","              mini_batch_size=32,\n","              anneal_factor=0.5,\n","              patience=5,\n","              max_epochs=10)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["2019-11-21 23:49:23,980 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:23,988 Model: \"TextClassifier(\n","  (document_embeddings): DocumentRNNEmbeddings(\n","    (embeddings): StackedEmbeddings(\n","      (list_embedding_0): XLNetEmbeddings(\n","        model=0-xlnet-base-cased\n","        (model): XLNetModel(\n","          (word_embedding): Embedding(32000, 768)\n","          (layer): ModuleList(\n","            (0): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (3): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (4): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (5): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (6): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (7): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (8): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (9): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (10): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (11): XLNetLayer(\n","              (rel_attn): XLNetRelativeAttention(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (ff): XLNetFeedForward(\n","                (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","                (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (list_embedding_1): RoBERTaEmbeddings(\n","        (model): RobertaModel(\n","          (embeddings): RobertaEmbeddings(\n","            (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","            (position_embeddings): Embedding(514, 768, padding_idx=1)\n","            (token_type_embeddings): Embedding(1, 768)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (encoder): BertEncoder(\n","            (layer): ModuleList(\n","              (0): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (1): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (2): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (3): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (4): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (5): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (6): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (7): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (8): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (9): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (10): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (11): BertLayer(\n","                (attention): BertAttention(\n","                  (self): BertSelfAttention(\n","                    (query): Linear(in_features=768, out_features=768, bias=True)\n","                    (key): Linear(in_features=768, out_features=768, bias=True)\n","                    (value): Linear(in_features=768, out_features=768, bias=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                  (output): BertSelfOutput(\n","                    (dense): Linear(in_features=768, out_features=768, bias=True)\n","                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                    (dropout): Dropout(p=0.1, inplace=False)\n","                  )\n","                )\n","                (intermediate): BertIntermediate(\n","                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n","                )\n","                (output): BertOutput(\n","                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","          (pooler): BertPooler(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (activation): Tanh()\n","          )\n","        )\n","      )\n","    )\n","    (word_reprojection_map): Linear(in_features=2304, out_features=256, bias=True)\n","    (rnn): GRU(256, 512, batch_first=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Linear(in_features=512, out_features=2, bias=True)\n","  (loss_function): CrossEntropyLoss()\n",")\"\n","2019-11-21 23:49:23,989 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:23,991 Corpus: \"Corpus: 6831 train + 1708 dev + 37958 test sentences\"\n","2019-11-21 23:49:23,992 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:23,994 Parameters:\n","2019-11-21 23:49:23,995  - learning_rate: \"0.1\"\n","2019-11-21 23:49:23,996  - mini_batch_size: \"32\"\n","2019-11-21 23:49:23,997  - patience: \"5\"\n","2019-11-21 23:49:23,997  - anneal_factor: \"0.5\"\n","2019-11-21 23:49:23,998  - max_epochs: \"10\"\n","2019-11-21 23:49:23,999  - shuffle: \"True\"\n","2019-11-21 23:49:24,000  - train_with_dev: \"False\"\n","2019-11-21 23:49:24,001  - batch_growth_annealing: \"False\"\n","2019-11-21 23:49:24,002 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:24,003 Model training base path: \"resources/taggers/sentiment-yelp\"\n","2019-11-21 23:49:24,004 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:24,005 Device: cuda:0\n","2019-11-21 23:49:24,006 ----------------------------------------------------------------------------------------------------\n","2019-11-21 23:49:24,007 Embeddings storage mode: cpu\n","2019-11-21 23:49:24,011 ----------------------------------------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-d942dc8af639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0manneal_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m               max_epochs=10)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, anneal_factor, patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, batch_growth_annealing, shuffle, param_selection_mode, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, data_points)\u001b[0m\n\u001b[1;32m    115\u001b[0m     ) -> torch.tensor:\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         text_embedding_list = [\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m         \u001b[0;31m# embed words in the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mlengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0muse_scalar_mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_scalar_mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m             \u001b[0mbos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<s>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m             \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"</s>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m         )\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_get_transformer_sentence_embeddings\u001b[0;34m(sentences, tokenizer, model, name, layers, pooling_operation, use_scalar_mix, bos_token, eos_token)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                     \u001b[0msubword_start_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                     \u001b[0msubword_end_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen_subwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m                     \u001b[0muse_scalar_mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_scalar_mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m                 )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_extract_embeddings\u001b[0;34m(hidden_states, layers, pooling_operation, subword_start_idx, subword_end_idx, use_scalar_mix)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_scalar_mix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m         \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScalarMix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0msm_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mixture_size)\u001b[0m\n\u001b[1;32m    921\u001b[0m                     \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 )\n\u001b[0;32m--> 923\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             ]\n\u001b[1;32m    925\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    921\u001b[0m                     \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 )\n\u001b[0;32m--> 923\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             ]\n\u001b[1;32m    925\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"markdown","metadata":{"id":"UicAfKIl8SQT","colab_type":"text"},"source":["# **Test:**"]},{"cell_type":"code","metadata":{"id":"Jp9AHjEF4Sj0","colab_type":"code","outputId":"e67ba8d2-6a9d-4ed1-ca4e-9afc76e879e2","executionInfo":{"status":"ok","timestamp":1574037585704,"user_tz":360,"elapsed":1691,"user":{"displayName":"Payton Walker","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPs1T6TM9X-ZFb3qy-FRZg_09KzlL2RwOi0ldjhA=s64","userId":"07447174154653828546"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from flair.data import Sentence\n","from flair.models import TextClassifier\n","\n","classifier = TextClassifier.load('resources/taggers/sentiment-yelp/final-model.pt')\n","\n","# create example sentence\n","sentence = Sentence('France is the current world cup winner.')\n","\n","# predict class and print\n","classifier.predict(sentence)\n","\n","print(sentence.labels)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2019-11-18 00:39:43,165 loading file resources/taggers/ag-news/final-model.pt\n","[1 (0.7662146687507629)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"totwh2J8b_7G","colab_type":"text"},"source":["# **10-Fold Cross Validation**"]},{"cell_type":"code","metadata":{"id":"4Y6TVdf7cdLO","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split, KFold, cross_val_score\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIRmgwy38iqA","colab_type":"code","colab":{}},"source":["# Read in training and test data\n","input_data = pd.read_csv('data/TrainingData.csv',encoding = \"ISO-8859-1\",low_memory=False)\n","\n","# Get index of \"Botometer_Score\" column\n","idx_bot = input_data.columns.get_loc(\"Botometer_Score\")\n","\n","# Generate list of bot labels for all rows in train and test data\n","## 1 = Not-Bot, 0 = Bot\n","bot_labels = list(map(lambda x: 1 if x <= 1 else (0 if x >= 3.5 else np.nan), input_data['Botometer_Score']))\n","\n","# Insert the new column of bot labels at the position immediately after the \"Botometer_Score\" column\n","input_data.insert(idx_bot+1, \"Bot_or_Not_Bot\", bot_labels, True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddFAZJBncGDm","colab_type":"code","colab":{}},"source":["# Filter data to only include rows that are labelled \"Bot\" or \"Not-Bot\"\n","input_data_filtered = input_data[(input_data[\"Bot_or_Not_Bot\"] == 1) | (input_data[\"Bot_or_Not_Bot\"] == 0)]\n","\n","# Filter data to remove rows with nan values in verified and default_profile columns\n","input_data_filtered = input_data_filtered[(input_data_filtered[\"verified\"] == True) | (input_data_filtered[\"verified\"] == False)]\n","input_data_filtered = input_data_filtered[(input_data_filtered[\"default_profile\"] == True) | (input_data_filtered[\"default_profile\"] == False)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKWF39NYcGxc","colab_type":"code","colab":{}},"source":["# Split data into train and test sets\n","test_data, train_data = train_test_split(input_data_filtered, test_size=0.33, stratify=input_data_filtered[\"Bot_or_Not_Bot\"])\n","\n","# Extract attribute columns into new table.\n","train_attr = train_data[['Botometer_Score', 'Bot_or_Not_Bot', 'followers_count', 'friends_count', 'listed_count', 'favourites_count', 'verified', 'default_profile']]\n","test_attr = test_data[['Botometer_Score', 'Bot_or_Not_Bot', 'followers_count', 'friends_count', 'listed_count', 'favourites_count', 'verified', 'default_profile']]\n","\n","# Extract label column into new table\n","train_label = train_data[['Bot_or_Not_Bot']]\n","test_label = test_data[['Bot_or_Not_Bot']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Y_BpzP_cOmp","colab_type":"text"},"source":["**Testing:**"]},{"cell_type":"code","metadata":{"id":"_EVe95y3cKfl","colab_type":"code","colab":{}},"source":["X = train_attr.values\n","Y = train_label.values\n","\n","actual = np.array(test_label)\n","actual"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvNPHfXYcRFh","colab_type":"code","colab":{}},"source":["clf_DT = tree.DecisionTreeClassifier()\n","clf_DT = clf_DT.fit(X, Y)\n","\n","scores = cross_val_score(clf_DT, X, Y, cv=10)\n","fscore = scores.mean()\n","\n","predicted = clf_DT.predict(test_attr)\n","pred = np.array(predicted)\n","pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxLeAkV_ch9q","colab_type":"code","colab":{}},"source":["accuracy = accuracy_score(actual, pred) * 100\n","precision = precision_score(actual, pred) * 100\n","recall = recall_score(actual, pred) * 100\n","f1 = f1_score(actual, pred)\n","\n","print ('Accuracy is {:.4f}'.format(accuracy))\n","print('Precision is {:.4f}'.format(precision))\n","print('Recall is {:.4f}'.format(recall))\n","print('F1 Score is {:.4f}'.format(f1))\n","print('10-Fold CV Score is {:.4f}'.format(fscore))"],"execution_count":0,"outputs":[]}]}